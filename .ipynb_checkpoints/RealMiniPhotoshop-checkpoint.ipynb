{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82106\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from PyQt5 import QtCore, QtWidgets, QtGui\n",
    "from PyQt5.QtGui import QImage\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QTabWidget, QVBoxLayout\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from math import acos, pi, sqrt\n",
    "import io\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Startvidieo(QtCore.QObject):\n",
    "\n",
    "    VideoSignal1 = QtCore.pyqtSignal(QtGui.QImage)\n",
    "\n",
    "    def __init__(self, parent=None):\n",
    "        super(Startvidieo, self).__init__(parent)\n",
    "    \n",
    "    def convolution_color(self, array, f):\n",
    "        a = (len(f)-1)//2\n",
    "        # boundery를 0으로 채운다\n",
    "        img_pad = np.pad(array, ((a,a),(a,a),(0,0)),'constant', constant_values=0)\n",
    "\n",
    "        #convolution을 위해 2번 뒤집는다\n",
    "        mask = np.rot90(f)\n",
    "        mask = np.rot90(mask)\n",
    "\n",
    "        #color img 이므로 3차원으로 배열 설정\n",
    "        result_img = np.zeros((len(array),len(array[0]),3))\n",
    "        result_img = result_img.astype('float32')\n",
    "\n",
    "        for i in range(len(result_img)):\n",
    "            for j in range(len(result_img[0])):\n",
    "                result_img[i][j][0] = np.sum(img_pad[i:i+len(f), j:j+len(f),0]*mask)\n",
    "                result_img[i][j][1] = np.sum(img_pad[i:i+len(f), j:j+len(f),1]*mask)\n",
    "                result_img[i][j][2] = np.sum(img_pad[i:i+len(f), j:j+len(f),2]*mask)\n",
    "        return result_img\n",
    "    \n",
    "    def convolution(self, array, f):\n",
    "        a = (len(f)-1)//2\n",
    "        # boundery를 0으로 채운다\n",
    "        img_pad = np.pad(array, ((a,a),(a,a)),'constant')\n",
    "\n",
    "        #convolution을 위해 2번 뒤집는다\n",
    "        mask = np.rot90(f)\n",
    "        mask = np.rot90(mask)\n",
    "\n",
    "        result_img = np.zeros((len(array), len(array[0])))\n",
    "        result_img = result_img.astype('float32')\n",
    "\n",
    "        for i in range(len(result_img)):\n",
    "            for j in range(len(result_img[0])):\n",
    "                result_img[i][j] = np.sum(img_pad[i:i+len(f),j:j+len(f)]*mask)\n",
    "\n",
    "        return result_img\n",
    "    \n",
    "    def gaussian2D(self, sigma):\n",
    "        # 두 벡터를 외적하여 x,y 2차원 mask를 생성\n",
    "        result = np.outer(self.gaussian1D(sigma),self.gaussian1D(sigma))\n",
    "        total = np.sum(result)\n",
    "        result/=total\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def gaussian1D(self, sigma):\n",
    "        a = sigma\n",
    "\n",
    "        if a % 2 == 0: #mask size가 짝수일 경우 1을 키운다\n",
    "            a+=1\n",
    "\n",
    "        a2 = a/2\n",
    "        filter_size = np.array(range(-int(a/2),int(a/2)+1))\n",
    "        result = np.zeros(len(filter_size))\n",
    "\n",
    "        for i in range(len(filter_size)):\n",
    "            x = i-a2\n",
    "            result[i] =  float(np.exp(-(x**2)/(2*sigma**2)) / (2*3.14*sigma**2)) #가우시안 공식\n",
    "\n",
    "        total = np.sum(result)\n",
    "        result/=total\n",
    "\n",
    "        return result\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def gaussianFiltering_color(self, name):\n",
    "        img = cv2.imread(\"./example/hw2/%s\" %name)\n",
    "\n",
    "        if img is None:\n",
    "            img = cv2.imread(\"./example/hw2/lover.jpg\")\n",
    "        \n",
    "        img_arr = np.asarray(img)\n",
    "        img_arr = img_arr.astype('float32')\n",
    "        \n",
    "        if len(img.shape) == 3: # 컬러 이미지\n",
    "            H, W, C = img.shape\n",
    "            img_arr = self.convolution_color(img_arr, self.gaussian2D(10))\n",
    "            img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        else:  # 흑백 이미지\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            H, W, C = img.shape\n",
    "            img_arr = self.convolution(img_arr, self.gaussian2D(10))\n",
    "\n",
    "        img_result = img_arr.astype('uint8')\n",
    "        img_result = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(\"./result/gaussianFilter.png\", img_result) \n",
    "\n",
    "        cv2.imshow(\"gaussianFilter\",img_result)\n",
    "        cv2.waitKey()\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def median_color(self, name):\n",
    "        img = cv2.imread(\"./example/hw2/%s\" %name)\n",
    "\n",
    "        if img is None:\n",
    "            img = cv2.imread(\"./example/hw2/lover.jpg\")\n",
    "\n",
    "        height, width, channel = img.shape\n",
    "\n",
    "        # 결과 배열 생성\n",
    "        out1 = np.zeros((height + 2, width + 2, channel), dtype=np.float) \n",
    "        out1[1: 1 + height, 1: 1 + width] = img.copy().astype(np.float)\n",
    "        temp1 = out1.copy()\n",
    "\n",
    "        mask = 3\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width): \n",
    "                for k in range(channel): \n",
    "                    out1[1 + i, 1 + j, k] = np.median(temp1[i:i + 15, j:j + 15, k])\n",
    "\n",
    "\n",
    "        out1 = out1[1:1 + height, 1:1 + width].astype(np.uint8) \n",
    "        cv2.imwrite(\"./result/medianFilterColor.png\", out1) \n",
    "\n",
    "        out = cv2.resize(out1, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "        out = QImage(out.data, 640, 480, out.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(out)\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def averageFilter(self, name):\n",
    "        name = str(name)\n",
    "        print(name)\n",
    "        img = cv2.imread(\"./example/hw2/%s\" %name)\n",
    "\n",
    "        if img is None:\n",
    "            img = cv2.imread(\"./example/hw2/Fig0504(i)(salt-pepper-noise).jpg\")\n",
    "\n",
    "        if len(img.shape) == 3: # 컬러 이미지\n",
    "            H, W, C = img.shape\n",
    "        else:  # 흑백 이미지\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            H, W, C = img.shape\n",
    "\n",
    "        pad = 3 // 2\n",
    "        out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n",
    "        out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n",
    "\n",
    "        # mask 생성\n",
    "        mask = np.ones((3, 3))/3**2\n",
    "\n",
    "        tmp = out.copy()\n",
    "\n",
    "        for i in range(H): \n",
    "            for j in range(W): \n",
    "                for k in range(C): \n",
    "                    out[pad + i, pad + j, k] = np.sum(mask * tmp[i: i + 3, j: j + 3, k])\n",
    "\n",
    "        # 0~255사이의 값으로 변환\n",
    "        out = np.clip(out, 0, 255) \n",
    "        out = out[pad: pad + H, pad: pad + W].astype(np.uint8) \n",
    "        cv2.imwrite(\"./result/averageFilterGray.png\", out)\n",
    "        \n",
    "        out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "        out = cv2.resize(out, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        out = QImage(out.data, 640, 480, out.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(out)\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def handDetection(self,name):\n",
    "        cap = cv2.VideoCapture('./example/hw3/%s' %name)\n",
    "        k = cap.isOpened()\n",
    "\n",
    "        if k==False:\n",
    "            cap.open(\"./example/hw3/Hand Video2.mov\")\n",
    "\n",
    "        width = int(cap.get(3)) # 가로 길이\n",
    "        height = int(cap.get(4)) # 세로 길이\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        # 동영상을 output으로 저장할 때\n",
    "        fcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')\n",
    "        out = cv2.VideoWriter('./result/output.avi', fcc, fps, (width, height))\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                ret, image = cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                #1. 전처리\n",
    "                image = cv2.GaussianBlur(image, (5,5),0)\n",
    "\n",
    "                #2.피부 검출\n",
    "                YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "                mask_hand = cv2.inRange(YCrCb,np.array([0,138,76]),np.array([255,175,127]))\n",
    "                mask_color = cv2.bitwise_and(image,image, mask=mask_hand)\n",
    "\n",
    "                #3. 후처리\n",
    "                mask_color = cv2.erode(mask_color,None,1)\n",
    "                out.write(mask_color)\n",
    "                \n",
    "                mask_color = cv2.cvtColor(mask_color, cv2.COLOR_BGR2RGB)\n",
    "                mask_color = cv2.resize(mask_color, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "                mask_color = QImage(mask_color.data, 640, 480, mask_color.strides[0], QImage.Format_RGB888)\n",
    "                self.VideoSignal1.emit(mask_color)\n",
    "\n",
    "                loop = QtCore.QEventLoop()\n",
    "                QtCore.QTimer.singleShot(25, loop.quit) #25 ms\n",
    "                loop.exec_()\n",
    "            except KeyboardInterrupt: break\n",
    "        if cap.isOpened():\n",
    "            cap.release()\n",
    "        if out.isOpened():\n",
    "            out.release()\n",
    "        \n",
    "    @QtCore.pyqtSlot()\n",
    "    def get_background(self, name):\n",
    "        cap = cv2.VideoCapture('./example/hw3/%s' %name)\n",
    "        k = cap.isOpened()\n",
    "\n",
    "        if k==False:\n",
    "            cap.open(\"./example/hw3/Project_outdoor video1.mov\")\n",
    "\n",
    "        width = int(cap.get(3)) # 가로 길이\n",
    "        height = int(cap.get(4)) # 세로 길이\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        back_img = np.zeros(shape=(height,width,3),dtype=np.float32)\n",
    "        count = 0\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                ret, image = cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                count += 1\n",
    "                cv2.accumulate(image, back_img)\n",
    "                average_back = back_img/count\n",
    "                result_img = cv2.convertScaleAbs(average_back)\n",
    "                \n",
    "                temp_img = cv2.resize(result_img, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "                temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB)\n",
    "                temp_img = QImage(temp_img.data, 640, 480, temp_img.strides[0], QImage.Format_RGB888)\n",
    "                self.VideoSignal1.emit(temp_img)\n",
    "\n",
    "                loop = QtCore.QEventLoop()\n",
    "                QtCore.QTimer.singleShot(25, loop.quit) #25 ms\n",
    "                loop.exec_()\n",
    "            except KeyboardInterrupt: break\n",
    "        if cap.isOpened():\n",
    "            cap.release()\n",
    "        cv2.imwrite('./background/back_img.png',result_img)\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def vehicleDetection(self, name):\n",
    "        cap = cv2.VideoCapture('./example/hw3/%s' %name)\n",
    "        k = cap.isOpened()\n",
    "\n",
    "        if k==False:\n",
    "            cap.open(\"./example/hw3/Project_outdoor video1.mov\")\n",
    "\n",
    "        width = int(cap.get(3)) # 가로 길이\n",
    "        height = int(cap.get(4)) # 세로 길이\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        back_img = cv2.imread('./background/back_img.png')\n",
    "        back_img = cv2.resize(back_img, dsize=(width,height), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # 동영상을 output으로 저장할 때\n",
    "        fcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')\n",
    "        out = cv2.VideoWriter('./result/output.avi', fcc, fps, (width, height))\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                ret, image = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                sub_img = cv2.absdiff(image, back_img)\n",
    "\n",
    "                B,G,R = cv2.split(sub_img)\n",
    "                ret,B = cv2.threshold(B,35,255,cv2.THRESH_BINARY)\n",
    "                ret,G = cv2.threshold(G,35,255,cv2.THRESH_BINARY)\n",
    "                ret,R = cv2.threshold(R,35,255,cv2.THRESH_BINARY)\n",
    "\n",
    "                thres_img = cv2.bitwise_or(B,G)\n",
    "                thres_img = cv2.bitwise_or(R,thres_img)\n",
    "\n",
    "                thres_img = cv2.dilate(thres_img,None,1)\n",
    "                thres_img = cv2.erode(thres_img,None, 3)\n",
    "\n",
    "                box_round,temp = cv2.findContours(thres_img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "                for i, now in enumerate(box_round):\n",
    "                    area = cv2.contourArea(now)\n",
    "                    if area>110:\n",
    "                        x,y,width,height = cv2.boundingRect(now)\n",
    "                        cv2.rectangle(image,(x,y),(x+width,y+height),(0,255, 0),2)\n",
    "                out.write(image)\n",
    "                \n",
    "                temp_img = cv2.resize(image, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "                temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB)\n",
    "                temp_img = QImage(temp_img.data, 640, 480, temp_img.strides[0], QImage.Format_RGB888)\n",
    "                self.VideoSignal1.emit(temp_img)\n",
    "\n",
    "                loop = QtCore.QEventLoop()\n",
    "                QtCore.QTimer.singleShot(25, loop.quit) #25 ms\n",
    "                loop.exec_()\n",
    "            except KeyboardInterrupt: break\n",
    "        if cap.isOpened():\n",
    "            cap.release()\n",
    "        if out.isOpened():\n",
    "            out.release()\n",
    "    \n",
    "    \n",
    "    def gradient(self, img, size, mask):\n",
    "        if len(img.shape) == 3: \n",
    "            H, W, C = img.shape\n",
    "        else: \n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            H, W, C = img.shape\n",
    "\n",
    "        pad = size // 2\n",
    "        out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n",
    "        out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n",
    "\n",
    "        tmp = out.copy()\n",
    "\n",
    "        for i in range(H): \n",
    "            for j in range(W): \n",
    "                for k in range(C): \n",
    "                    out[pad + i, pad + j, k] = np.sum(mask * tmp[i: i + size, j: j + size, k]) \n",
    "        out = np.clip(out, 0, 255) \n",
    "        out = out[pad: pad + H, pad: pad + W].astype(np.uint8) \n",
    "\n",
    "        return out\n",
    "\n",
    "    @QtCore.pyqtSlot()\n",
    "    def sobelEdgeDetection(self, name):\n",
    "        img = cv2.imread(\"./example/hw2/%s\" %name)\n",
    "\n",
    "        if img is None:\n",
    "            img = cv2.imread(\"./example/hw2/Fig0327(a)(tungsten_original).jpg\")\n",
    "            \n",
    "        kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "        kernel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
    "\n",
    "        out_x = self.gradient(img, 3, kernel_x)\n",
    "        out_y = self.gradient(img, 3, kernel_y)\n",
    "\n",
    "        merged = out_x+out_y\n",
    "\n",
    "        cv2.imwrite(\"./result/sobelEdgeDetection.png\", merged) \n",
    "\n",
    "        out = cv2.resize(merged, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        out = QImage(out.data, 640, 480, out.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(out)\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def highBoostFilter(self, name):\n",
    "        img = cv2.imread(\"./example/hw2/%s\" %name)\n",
    "\n",
    "        if img is None:\n",
    "            img = cv2.imread(\"./example/hw2/Fig0327(a)(tungsten_original).jpg\")\n",
    "\n",
    "        A = 1.2\n",
    "\n",
    "        mask2 = np.array([[-1,-1,-1],\n",
    "                          [-1,A+8,-1],\n",
    "                          [-1,-1,-1]])\n",
    "\n",
    "        result2 = self.convolution2(img, 3, mask2)\n",
    "        cv2.imwrite(\"./result/highBoostFilterGray.png\", result2) \n",
    "\n",
    "        result2 = cv2.resize(result2, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        result2 = QImage(result2.data, 640, 480, result2.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(result2)\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def cannyEdgeDetection(self, name):\n",
    "        img = cv2.imread(\"./example/hw2/%s\" %name)\n",
    "\n",
    "        if img is None:\n",
    "            img = cv2.imread(\"./example/hw2/Fig0327(a)(tungsten_original).jpg\")\n",
    "\n",
    "        out2 = cv2.Canny(img, 50, 100)\n",
    "\n",
    "        cv2.imwrite(\"./result/cannyEdgeDetection.png\", out2) \n",
    "\n",
    "        out = cv2.resize(out2, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "        out = QImage(out.data, 640, 480, out.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(out)\n",
    "#         cv2.imshow(\"canny\",out2)\n",
    "#         cv2.waitKey()\n",
    "    \n",
    "    def LoG_filter(self, img, size, mask):\n",
    "        if len(img.shape) == 3: \n",
    "            H, W, C = img.shape\n",
    "        else: \n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            H, W, C = img.shape\n",
    "\n",
    "        pad = size // 2\n",
    "        out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n",
    "        out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n",
    "\n",
    "        tmp = out.copy()\n",
    "\n",
    "        for i in range(H): \n",
    "            for j in range(W): \n",
    "                for k in range(C): \n",
    "                    out[pad + i, pad + j, k] = np.sum(mask * tmp[i: i + size, j: j + size, k]) \n",
    "        out = np.clip(out, 0, 255) \n",
    "        out = out[pad: pad + H, pad: pad + W].astype(np.uint8) \n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def logEdgeDetection(self, name):\n",
    "        img = cv2.imread(\"./example/hw2/%s\" %name)\n",
    "\n",
    "        if img is None:\n",
    "            img = cv2.imread(\"./example/hw2/Fig0327(a)(tungsten_original).jpg\")\n",
    "        \n",
    "        kernel = np.array([[0,0,1,0,0], [0,1,2,1,0], [1,2,-16,2,1], [0,1,2,1,0],[0,0,1,0,0]])\n",
    "        out2 = self.LoG_filter(img, 5, kernel)\n",
    "\n",
    "        cv2.imwrite(\"./result/LoGEdgeDetection.png\", out2) \n",
    "\n",
    "        result2 = cv2.resize(out2, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        result2 = QImage(result2.data, 640, 480, result2.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(result2)\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def negative(self, name):\n",
    "        src = cv2.imread(\"./example/hw1/%s\" %name)\n",
    "\n",
    "        if src is None:\n",
    "            src = cv2.imread(\"./example/hw1/3. Negative test.tif\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        height, width = src.shape[0], src.shape[1]\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                src[i][j] = 255. - src[i][j]\n",
    "\n",
    "        cv2.imwrite(\"./result/negative.png\", src) \n",
    "\n",
    "        out = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "        out = QImage(out.data, 640, 480, out.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(out)\n",
    "#         cv2.imshow(\"negative\",src)\n",
    "#         cv2.waitKey()\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def histogramEqualization(self, name):\n",
    "        src = cv2.imread(\"./example/hw1/%s\" %name)\n",
    "\n",
    "        if src is None:\n",
    "            src = cv2.imread(\"./example/hw1/3. Negative test.tif\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        height, width = src.shape[0], src.shape[1]\n",
    "\n",
    "        histogram = np.zeros(256)\n",
    "        lookUpTable = np.zeros(256)\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                histogram[src[i][j]] += 1\n",
    "\n",
    "        sumv = 0.0\n",
    "        scale_factor = 255.0/(height * width)\n",
    "\n",
    "        for i in range(256):\n",
    "            sumv += histogram[i]\n",
    "            lookUpTable[i] = round( sumv * scale_factor )\n",
    "\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                src[i][j] = lookUpTable[src[i][j]]\n",
    "\n",
    "        cv2.imwrite(\"./result/histogramEqualization.png\", src) \n",
    "\n",
    "        out = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "        out = QImage(out.data, 640, 480, out.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(out)\n",
    "#         cv2.imshow(\"histogramEqualization\",src)\n",
    "#         cv2.waitKey()\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def powerLawTransformations(self, name):\n",
    "        src = cv2.imread(\"./example/hw1/%s\" %name)\n",
    "\n",
    "        if src is None:\n",
    "            src = cv2.imread(\"./example/hw1/3. Negative test.tif\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        height, width = src.shape[0], src.shape[1]\n",
    "\n",
    "        r = 1.2\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                src[i][j] = 255*(src[i][j]/255.)**r\n",
    "\n",
    "        cv2.imwrite(\"./result/powerLawTransformations.png\", src) \n",
    "        \n",
    "        out = cv2.resize(src, dsize=(640, 480), interpolation=cv2.INTER_LINEAR)\n",
    "        out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "        out = QImage(out.data, 640, 480, out.strides[0], QImage.Format_RGB888)\n",
    "        self.VideoSignal1.emit(out)\n",
    "    \n",
    "    def convolution2(self, img, size, mask):\n",
    "        if len(img.shape) == 3: # 컬러 이미지\n",
    "            H, W, C = img.shape\n",
    "        else:  # 흑백 이미지\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            H, W, C = img.shape\n",
    "\n",
    "        pad = size // 2\n",
    "        out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n",
    "        out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n",
    "\n",
    "        tmp = out.copy()\n",
    "\n",
    "        for i in range(H): \n",
    "            for j in range(W): \n",
    "                for k in range(C): \n",
    "                    out[pad + i, pad + j, k] = np.sum(mask * tmp[i: i + size, j: j + size, k])\n",
    "\n",
    "        # 0~255사이의 값으로 변환\n",
    "        out = np.clip(out, 0, 255) \n",
    "        out = out[pad: pad + H, pad: pad + W].astype(np.uint8) \n",
    "        return out\n",
    "    \n",
    "\n",
    "class ImageViewer(QtWidgets.QWidget):\n",
    "    def __init__(self, parent=None):\n",
    "        super(ImageViewer, self).__init__(parent)\n",
    "        self.image = QtGui.QImage()\n",
    "        self.setAttribute(QtCore.Qt.WA_OpaquePaintEvent)\n",
    "\n",
    "    def paintEvent(self, event):\n",
    "        painter = QtGui.QPainter(self)\n",
    "        painter.drawImage(0, 0, self.image)\n",
    "        self.image = QtGui.QImage()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Test')\n",
    "\n",
    "    @QtCore.pyqtSlot(QtGui.QImage)\n",
    "    def setImage(self, image):\n",
    "        if image.isNull():\n",
    "            print(\"Viewer Dropped frame!\")\n",
    "\n",
    "        self.image = image\n",
    "        if image.size() != self.size():\n",
    "            self.setFixedSize(image.size())\n",
    "        self.update()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    \n",
    "    #thread\n",
    "    thread = QtCore.QThread()\n",
    "    thread.start()\n",
    "    vid = Startvidieo()\n",
    "    vid.moveToThread(thread)\n",
    "    image_viewer1 = ImageViewer()\n",
    "    vid.VideoSignal1.connect(image_viewer1.setImage)\n",
    "    \n",
    "    #버튼 및 텍스트 생성\n",
    "    textEdit = QtWidgets.QTextEdit()\n",
    "    \n",
    "    push_button1 = QtWidgets.QPushButton('hand detection')\n",
    "    push_button1.clicked.connect(lambda: vid.handDetection(textEdit.toPlainText()))\n",
    "    push_button2 = QtWidgets.QPushButton('get background')\n",
    "    push_button2.clicked.connect(lambda: vid.get_background(textEdit.toPlainText()))\n",
    "    push_button3 = QtWidgets.QPushButton('vehicle detection')\n",
    "    push_button3.clicked.connect(lambda: vid.vehicleDetection(textEdit.toPlainText()))\n",
    "    \n",
    "    push_button4 = QtWidgets.QPushButton('average filter')\n",
    "    push_button4.clicked.connect(lambda: vid.averageFilter(textEdit.toPlainText()))\n",
    "    push_button5 = QtWidgets.QPushButton('gaussian filter-color')\n",
    "    push_button5.clicked.connect(lambda: vid.gaussianFiltering_color(textEdit.toPlainText()))\n",
    "    push_button6 = QtWidgets.QPushButton('median filter')\n",
    "    push_button6.clicked.connect(lambda: vid.median_color(textEdit.toPlainText()))\n",
    "    \n",
    "    push_button7 = QtWidgets.QPushButton('highBoost filter')\n",
    "    push_button7.clicked.connect(lambda: vid.highBoostFilter(textEdit.toPlainText()))\n",
    "    push_button8 = QtWidgets.QPushButton('gradiant edge detection')\n",
    "    push_button8.clicked.connect(lambda: vid.sobelEdgeDetection(textEdit.toPlainText()))\n",
    "    push_button9 = QtWidgets.QPushButton('LoG edge detection')\n",
    "    push_button9.clicked.connect(lambda: vid.logEdgeDetection(textEdit.toPlainText()))\n",
    "    push_button10 = QtWidgets.QPushButton('canny edge detection')\n",
    "    push_button10.clicked.connect(lambda: vid.cannyEdgeDetection(textEdit.toPlainText()))\n",
    "    \n",
    "    push_button11 = QtWidgets.QPushButton('histogram equalization')\n",
    "    push_button11.clicked.connect(lambda: vid.histogramEqualization(textEdit.toPlainText()))\n",
    "    push_button12 = QtWidgets.QPushButton('negative')\n",
    "    push_button12.clicked.connect(lambda: vid.negative(textEdit.toPlainText()))\n",
    "    push_button13 = QtWidgets.QPushButton('power law transformation')\n",
    "    push_button13.clicked.connect(lambda: vid.powerLawTransformations(textEdit.toPlainText()))\n",
    "    \n",
    "    #버튼 레이아웃\n",
    "    horizontal_layout0 = QtWidgets.QHBoxLayout()\n",
    "    horizontal_layout0.addWidget(textEdit)\n",
    "    \n",
    "    horizontal_layout = QtWidgets.QHBoxLayout()\n",
    "    horizontal_layout.addWidget(push_button1)\n",
    "    horizontal_layout.addWidget(push_button2)\n",
    "    horizontal_layout.addWidget(push_button3)\n",
    "    \n",
    "    horizontal_layout2 = QtWidgets.QHBoxLayout()\n",
    "    horizontal_layout2.addWidget(push_button4)\n",
    "    horizontal_layout2.addWidget(push_button5)\n",
    "    horizontal_layout2.addWidget(push_button6)\n",
    "    \n",
    "    horizontal_layout3 = QtWidgets.QHBoxLayout()\n",
    "    horizontal_layout3.addWidget(push_button7)\n",
    "    horizontal_layout3.addWidget(push_button8)\n",
    "    horizontal_layout3.addWidget(push_button9)\n",
    "    horizontal_layout3.addWidget(push_button10)\n",
    "    \n",
    "    horizontal_layout4 = QtWidgets.QHBoxLayout()\n",
    "    horizontal_layout4.addWidget(push_button11)\n",
    "    horizontal_layout4.addWidget(push_button12)\n",
    "    horizontal_layout4.addWidget(push_button13)\n",
    "    \n",
    "    #전체 레이아웃\n",
    "    vertical_layout = QtWidgets.QVBoxLayout()\n",
    "    vertical_layout.addWidget(image_viewer1)\n",
    "    vertical_layout.addLayout(horizontal_layout0)\n",
    "    vertical_layout.addLayout(horizontal_layout)\n",
    "    vertical_layout.addLayout(horizontal_layout2)\n",
    "    vertical_layout.addLayout(horizontal_layout3)\n",
    "    vertical_layout.addLayout(horizontal_layout4)\n",
    "    \n",
    "    layout_widget = QtWidgets.QWidget()\n",
    "    layout_widget.setLayout(vertical_layout)\n",
    "    \n",
    "    #show window\n",
    "    main_window = QtWidgets.QMainWindow()\n",
    "    main_window.setCentralWidget(layout_widget)\n",
    "    main_window.setWindowTitle('Mini Photoshop by Jiwoo Hong')\n",
    "    main_window.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
